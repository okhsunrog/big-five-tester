# Big Five AI Analysis Configuration
# ==================================
#
# This file configures the AI pipeline for personality analysis.
# Copy this file to `ai_config.toml` and adjust settings as needed.
#
# Environment variable AI_CONFIG_PATH can override the config file location.
# Default: ./ai_config.toml

# =============================================================================
# Shared Safeguard Configuration (applies to all models)
# =============================================================================
# Checks user-provided context for prompt injection attempts before analysis.
# Uses a cheap/fast model to classify input as SAFE or UNSAFE.

[safeguard]
enabled = true
# gpt-oss-safeguard-20b: fast & accurate for prompt injection detection
model = "openai/gpt-oss-safeguard-20b"
max_tokens = 1024

[safeguard.api]
provider = "openai"
api_key_env = "OPENROUTER_API_KEY"
api_url = "https://openrouter.ai/api/v1/chat/completions"

# =============================================================================
# Model Presets (order here = order in UI dropdown)
# =============================================================================
# Each model has its own configuration:
# - id: Unique identifier (used internally)
# - display_name: Shown in UI dropdown
# - model: Model identifier for the API
# - source_lang: Language the model generates in ("en", "zh", "ru")
# - default: Set to true for the default model (only one!)
# - api: API configuration for this model
# - translation: Optional translation settings (if source_lang != interface language)

# --- DeepSeek V3.2 (Chinese source) ---
[[models]]
id = "deepseek-v3.2"
display_name = "DeepSeek V3.2"
model = "deepseek/deepseek-v3.2"
source_lang = "zh"
max_tokens = 8192

[models.api]
provider = "openai"
api_key_env = "OPENROUTER_API_KEY"
api_url = "https://openrouter.ai/api/v1/chat/completions"

[models.translation]
model = "google/gemini-2.5-flash-lite"
max_tokens = 8192

[models.translation.api]
provider = "openai"
api_key_env = "OPENROUTER_API_KEY"
api_url = "https://openrouter.ai/api/v1/chat/completions"

# --- Claude Opus 4.5 (English source, via Anthropic API, DEFAULT) ---
[[models]]
id = "claude-opus-4.5"
display_name = "Claude Opus 4.5"
model = "claude-opus-4-5-20251101"
source_lang = "en"
max_tokens = 8192
default = true

[models.api]
provider = "anthropic"
api_key_env = "ANTHROPIC_API_KEY"

[models.translation]
model = "google/gemini-2.5-flash-lite"
max_tokens = 8192

[models.translation.api]
provider = "openai"
api_key_env = "OPENROUTER_API_KEY"
api_url = "https://openrouter.ai/api/v1/chat/completions"

# --- GPT-5.2 (English source) ---
[[models]]
id = "gpt-5.2"
display_name = "GPT-5.2"
model = "openai/gpt-5.2"
source_lang = "en"
max_tokens = 8192

[models.api]
provider = "openai"
api_key_env = "OPENROUTER_API_KEY"
api_url = "https://openrouter.ai/api/v1/chat/completions"

[models.translation]
model = "google/gemini-2.5-flash-lite"
max_tokens = 8192

[models.translation.api]
provider = "openai"
api_key_env = "OPENROUTER_API_KEY"
api_url = "https://openrouter.ai/api/v1/chat/completions"

# --- Qwen 3 235B (Chinese source) ---
[[models]]
id = "qwen-3-235b"
display_name = "Qwen 3 235B"
model = "qwen/qwen3-235b-a22b-2507"
source_lang = "zh"
max_tokens = 8192

[models.api]
provider = "openai"
api_key_env = "OPENROUTER_API_KEY"
api_url = "https://openrouter.ai/api/v1/chat/completions"

[models.translation]
model = "google/gemini-2.5-flash-lite"
max_tokens = 8192

[models.translation.api]
provider = "openai"
api_key_env = "OPENROUTER_API_KEY"
api_url = "https://openrouter.ai/api/v1/chat/completions"

# =============================================================================
# How Translation Works
# =============================================================================
#
# Each model has a source_lang (its "native" language):
# - Chinese models (DeepSeek, Qwen): source_lang = "zh"
# - English models (Claude, GPT): source_lang = "en"
#
# When user's interface language differs from source_lang:
# 1. Analysis is generated in source_lang
# 2. Translation model translates to interface language
#
# When user's interface language matches source_lang:
# - Analysis is generated directly, no translation needed
#
# Example: User has Russian interface, picks DeepSeek:
# 1. DeepSeek generates analysis in Chinese
# 2. Gemini translates Chinese -> Russian
#
# Example: User has English interface, picks Claude:
# 1. Claude generates analysis in English
# 2. No translation needed (source = interface)

# =============================================================================
# Minimal Single-Model Configuration
# =============================================================================
# If you only need one model, you can use a simpler config:
#
# [safeguard]
# enabled = false
#
# [[models]]
# id = "default"
# display_name = "AI Analysis"
# model = "deepseek/deepseek-chat-v3-0324"
# source_lang = "en"
# default = true
#
# [models.api]
# provider = "openai"
# api_key_env = "OPENROUTER_API_KEY"
# api_url = "https://openrouter.ai/api/v1/chat/completions"
